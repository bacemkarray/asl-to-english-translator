{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import random\n",
    "\n",
    "import splitfolders\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,Dropout,Flatten,MaxPooling2D, BatchNormalization,Input,concatenate\n",
    "from keras.callbacks import EarlyStopping,ReduceLROnPlateau\n",
    "from keras.utils import plot_model\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"asl_data_path\"\n",
    "\n",
    "# Dictionary to save our 36 classes\n",
    "categories = {  0: \"0\",\n",
    "                1: \"1\",\n",
    "                2: \"2\",\n",
    "                3: \"3\",\n",
    "                4: \"4\",\n",
    "                5: \"5\",\n",
    "                6: \"6\",\n",
    "                7: \"7\",\n",
    "                8: \"8\",\n",
    "                9: \"9\",\n",
    "                10: \"a\",\n",
    "                11: \"b\",\n",
    "                12: \"c\",\n",
    "                13: \"d\",\n",
    "                14: \"e\",\n",
    "                15: \"f\",\n",
    "                16: \"g\",\n",
    "                17: \"h\",\n",
    "                18: \"i\",\n",
    "                19: \"j\",\n",
    "                20: \"k\",\n",
    "                21: \"l\",\n",
    "                22: \"m\",\n",
    "                23: \"n\",\n",
    "                24: \"o\",\n",
    "                25: \"p\",\n",
    "                26: \"q\",\n",
    "                27: \"r\",\n",
    "                28: \"s\",\n",
    "                29: \"t\",\n",
    "                30: \"u\",\n",
    "                31: \"v\",\n",
    "                32: \"w\",\n",
    "                33: \"x\",\n",
    "                34: \"y\",\n",
    "                35: \"z\",\n",
    "            }\n",
    "\n",
    "def add_class_name_prefix(df, col_name):\n",
    "    df[col_name] = df[col_name].apply(\n",
    "        lambda x: x[re.search(\"_\", x).start() + 1 : re.search(\"_\", x).start() + 2]\n",
    "        + \"/\"\n",
    "        + x\n",
    "    )\n",
    "    return df\n",
    "\n",
    "\n",
    "# list conatining all the filenames in the dataset\n",
    "filenames_list = []\n",
    "# list to store the corresponding category, note that each folder of the dataset has one class of data\n",
    "categories_list = []\n",
    "\n",
    "for category in categories:\n",
    "    filenames = os.listdir(base_path + categories[category])\n",
    "    filenames_list = filenames_list + filenames\n",
    "    categories_list = categories_list + [category] * len(filenames)\n",
    "\n",
    "df = pd.DataFrame({\"filename\": filenames_list, \"category\": categories_list})\n",
    "df = add_class_name_prefix(df, \"filename\")\n",
    "\n",
    "# Shuffle the dataframe\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of elements =  2515\n"
     ]
    }
   ],
   "source": [
    "print(\"number of elements = \", len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2515 files [00:16, 154.62 files/s]\n"
     ]
    }
   ],
   "source": [
    "splitfolders.ratio(\"asl_data_path\",output=\"working_directory_path\", seed=1333, ratio=(0.8,0.1,0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale= 1.0 / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = \"train_data_path\"\n",
    "val_path = \"validation data path\"\n",
    "test_path = \"test_data_path\"\n",
    "\n",
    "batch = 32\n",
    "image_size = 200\n",
    "img_channel = 3\n",
    "n_classes = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2012 images belonging to 36 classes.\n",
      "Found 251 images belonging to 36 classes.\n",
      "Found 252 images belonging to 36 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data = datagen.flow_from_directory(directory= train_path, \n",
    "                                         target_size=(image_size,image_size), \n",
    "                                         batch_size = batch, \n",
    "                                         class_mode='categorical')\n",
    "\n",
    "val_data = datagen.flow_from_directory(directory= val_path, \n",
    "                                       target_size=(image_size,image_size), \n",
    "                                       batch_size = batch, \n",
    "                                       class_mode='categorical',\n",
    "                                       )\n",
    "\n",
    "test_data = datagen.flow_from_directory(directory= test_path, \n",
    "                                         target_size=(image_size,image_size), \n",
    "                                         batch_size = batch, \n",
    "                                         class_mode='categorical',\n",
    "                                         shuffle= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d (Conv2D)             (None, 200, 200, 32)      896       \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 200, 200, 32)      9248      \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2  (None, 100, 100, 32)      0         \n",
      " D)                                                              \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100, 100, 32)      0         \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 100, 100, 64)      18496     \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 100, 100, 64)      36928     \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPoolin  (None, 50, 50, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_1 (Dropout)         (None, 50, 50, 64)        0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 50, 50, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 50, 50, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 25, 25, 128)       0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 25, 25, 128)       0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 80000)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               40960512  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 128)               65664     \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 36)                4644      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 41317828 (157.62 MB)\n",
      "Trainable params: 41317828 (157.62 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "# input layer\n",
    "# Block 1\n",
    "model.add(Conv2D(32,3,activation='relu',padding='same',input_shape = (image_size,image_size,img_channel)))\n",
    "model.add(Conv2D(32,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.2))\n",
    "\n",
    "# Block 2\n",
    "model.add(Conv2D(64,3,activation='relu',padding='same'))\n",
    "model.add(Conv2D(64,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#Block 3\n",
    "model.add(Conv2D(128,3,activation='relu',padding='same'))\n",
    "model.add(Conv2D(128,3,activation='relu',padding='same'))\n",
    "#model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D(padding='same'))\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "# fully connected layer\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512,activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(128,activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "# output layer\n",
    "model.add(Dense(36, activation='softmax'))\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stoping = EarlyStopping(monitor='val_loss', \n",
    "                              min_delta=0.001,\n",
    "                              patience= 5,\n",
    "                              restore_best_weights= True, \n",
    "                              verbose = 0)\n",
    "\n",
    "reduce_learning_rate = ReduceLROnPlateau(monitor='val_accuracy', \n",
    "                                         patience = 2, \n",
    "                                         factor=0.5 , \n",
    "                                         verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy' , metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "63/63 [==============================] - 102s 2s/step - loss: 2.7005 - accuracy: 0.2634 - val_loss: 0.6655 - val_accuracy: 0.7649 - lr: 0.0010\n",
      "Epoch 2/30\n",
      "63/63 [==============================] - 95s 2s/step - loss: 0.7707 - accuracy: 0.7664 - val_loss: 0.2765 - val_accuracy: 0.9004 - lr: 0.0010\n",
      "Epoch 3/30\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.3311 - accuracy: 0.8862 - val_loss: 0.1823 - val_accuracy: 0.9402 - lr: 0.0010\n",
      "Epoch 4/30\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.2200 - accuracy: 0.9299 - val_loss: 0.1526 - val_accuracy: 0.9482 - lr: 0.0010\n",
      "Epoch 5/30\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.1347 - accuracy: 0.9597 - val_loss: 0.1385 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 6/30\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.0939 - accuracy: 0.9697 - val_loss: 0.1023 - val_accuracy: 0.9602 - lr: 0.0010\n",
      "Epoch 7/30\n",
      "63/63 [==============================] - 94s 1s/step - loss: 0.0964 - accuracy: 0.9712 - val_loss: 0.1338 - val_accuracy: 0.9522 - lr: 0.0010\n",
      "Epoch 8/30\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.0654 - accuracy: 0.9791 - val_loss: 0.0856 - val_accuracy: 0.9761 - lr: 0.0010\n",
      "Epoch 9/30\n",
      "63/63 [==============================] - 95s 2s/step - loss: 0.0518 - accuracy: 0.9811 - val_loss: 0.1372 - val_accuracy: 0.9721 - lr: 0.0010\n",
      "Epoch 10/30\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.0614 - accuracy: 0.9742 - val_loss: 0.1006 - val_accuracy: 0.9801 - lr: 0.0010\n",
      "Epoch 11/30\n",
      "63/63 [==============================] - 93s 1s/step - loss: 0.0390 - accuracy: 0.9866 - val_loss: 0.1786 - val_accuracy: 0.9681 - lr: 0.0010\n",
      "Epoch 12/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0619 - accuracy: 0.9821\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "63/63 [==============================] - 92s 1s/step - loss: 0.0619 - accuracy: 0.9821 - val_loss: 0.1007 - val_accuracy: 0.9641 - lr: 0.0010\n",
      "Epoch 13/30\n",
      "63/63 [==============================] - 96s 2s/step - loss: 0.0294 - accuracy: 0.9930 - val_loss: 0.0800 - val_accuracy: 0.9841 - lr: 5.0000e-04\n",
      "Epoch 14/30\n",
      "63/63 [==============================] - 94s 1s/step - loss: 0.0178 - accuracy: 0.9945 - val_loss: 0.1234 - val_accuracy: 0.9761 - lr: 5.0000e-04\n",
      "Epoch 15/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0201 - accuracy: 0.9935\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "63/63 [==============================] - 95s 2s/step - loss: 0.0201 - accuracy: 0.9935 - val_loss: 0.1187 - val_accuracy: 0.9641 - lr: 5.0000e-04\n",
      "Epoch 16/30\n",
      "63/63 [==============================] - 94s 1s/step - loss: 0.0127 - accuracy: 0.9950 - val_loss: 0.1227 - val_accuracy: 0.9761 - lr: 2.5000e-04\n",
      "Epoch 17/30\n",
      "63/63 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9960\n",
      "Epoch 17: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "63/63 [==============================] - 94s 1s/step - loss: 0.0076 - accuracy: 0.9960 - val_loss: 0.1076 - val_accuracy: 0.9801 - lr: 2.5000e-04\n",
      "Epoch 18/30\n",
      "63/63 [==============================] - 95s 2s/step - loss: 0.0105 - accuracy: 0.9965 - val_loss: 0.0947 - val_accuracy: 0.9801 - lr: 1.2500e-04\n"
     ]
    }
   ],
   "source": [
    "asl_class = model.fit(train_data, \n",
    "                      validation_data= val_data, \n",
    "                      epochs=30, \n",
    "                      callbacks=[early_stoping,reduce_learning_rate],\n",
    "                      verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for training data is: 99.9502956867218\n",
      "The Loss of the model for training data is: 0.0007713723462074995\n",
      "The accuracy of the model for validation data is: 98.40637445449829\n",
      "The Loss of the model for validation data is: 0.07997511327266693\n"
     ]
    }
   ],
   "source": [
    "# Evaluvate for train generator\n",
    "loss,acc = model.evaluate(train_data , verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for training data is:',acc*100)\n",
    "print('The Loss of the model for training data is:',loss)\n",
    "\n",
    "# Evaluvate for validation generator\n",
    "loss,acc = model.evaluate(val_data, verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for validation data is:',acc*100)\n",
    "print('The Loss of the model for validation data is:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy of the model for testing data is: 94.84127163887024\n",
      "The Loss of the model for testing data is: 0.3377110958099365\n"
     ]
    }
   ],
   "source": [
    "# prediction\n",
    "result = model.predict(test_data,verbose = 0)\n",
    "\n",
    "y_pred = np.argmax(result, axis = 1)\n",
    "\n",
    "y_true = test_data.labels\n",
    "\n",
    "# Evaluvate\n",
    "loss,acc = model.evaluate(test_data,verbose = 0)\n",
    "\n",
    "print('The accuracy of the model for testing data is:',acc*100)\n",
    "print('The Loss of the model for testing data is:',loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct predicted classes: 239\n",
      "Incorrect predicted classes: 13\n"
     ]
    }
   ],
   "source": [
    "p = y_pred\n",
    "y = y_true\n",
    "correct = np.nonzero(p==y)[0]\n",
    "incorrect = np.nonzero(p!=y)[0]\n",
    "\n",
    "print(\"Correct predicted classes:\",correct.shape[0])\n",
    "print(\"Incorrect predicted classes:\",incorrect.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"ASL_model.h5\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
